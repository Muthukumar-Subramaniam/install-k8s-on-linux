##Version : v2.0.1
- name: Upgrade system packages of all the cluster nodes
  hosts: k8s_cluster_ctrl_plane_node, k8s_cluster_worker_nodes 
  become: true
  tasks:
    - when: ansible_os_family == "RedHat"
      name: Upgrade the system packages ( RedHat based systems )
      dnf:
        update_cache: true
        name: "*"
        state: latest

    - when: ansible_os_family == "Debian"
      name: Upgrade the system packages ( Debian based systems )
      apt:
        update_cache: true
        upgrade: full
  
    - when: ansible_os_family == "Suse"
      name: Upgrade the system package ( Suse based systems )
      zypper:
        update_cache: true
        name: "*"
        state: latest


- name: Disable swap memory
  hosts: k8s_cluster_ctrl_plane_node, k8s_cluster_worker_nodes 
  become: true
  tasks:
    - name: Turn off swap if active
      command: swapoff -a

    - name: Remove swap entry from fstab
      lineinfile:
        backup: true
        dest: /etc/fstab
        regexp: '^.* swap .*$'
        state: absent


- name: Load required kernel modules and kernel parameters
  hosts: k8s_cluster_ctrl_plane_node, k8s_cluster_worker_nodes 
  become: true
  tasks:
    - name: Load overlay kernel module
      modprobe:
        name: overlay
        state: present

    - name: Load br_netfilter kernel module
      modprobe:
        name: br_netfilter
        state: present

    - name: Create /etc/modules-load.d/k8s.conf for the above loaded modules to be persistent
      blockinfile:
        create: true
        path: /etc/modules-load.d/k8s.conf
        block: |
          overlay
          br_netfilter
        state: present

    - name: Create /etc/sysctl.d/k8s.conf and update required kernel parameters to be persistent
      blockinfile:
        create: true
        path: /etc/sysctl.d/k8s.conf
        block: |
          net.ipv4.ip_forward = 1
          net.bridge.bridge-nf-call-iptables = 1
          net.bridge.bridge-nf-call-ip6tables = 1
        state: present

    - name: Re-load the system kernel parameters
      command: sysctl --system


- name: Install and configure latest version of containered using official binaries
  hosts: k8s_cluster_ctrl_plane_node, k8s_cluster_worker_nodes 
  become: true
  vars:
    var_containerd_temp_dir: "/tmp/containerd"
  tasks:
    - name: Get latest version information of containerd from GitHub API
      uri:
        url: https://api.github.com/repos/containerd/containerd/releases/latest
        return_content: true
      register: var_containerd_release

    - set_fact:
        var_containerd_version: "{{ var_containerd_release.json.tag_name }}"

    - debug:
        msg: |-
          Latest stable version to be installed of containerd is {{ var_containerd_version }}

    - name: Create /tmp/containerd to download the containerd binary
      file:
        path: "{{ var_containerd_temp_dir }}"
        state: directory
        mode: 0755

    - name: Download tarball of containerd binary from their official GitHub repo
      get_url:
        url: https://github.com/containerd/containerd/releases/download/{{ var_containerd_version }}/containerd-{{ var_containerd_version | regex_replace('v', '') }}-linux-amd64.tar.gz
        dest: "{{ var_containerd_temp_dir }}/containerd.tar.gz"

    - name: Extract containerd bin under /usr/local
      unarchive:
        remote_src: true
        src: "{{ var_containerd_temp_dir }}/containerd.tar.gz"
        dest: /usr/local 

    - name: Clean up /tmp/containerd
      file:
        path: "{{ var_containerd_temp_dir }}"
        state: absent

    - name: Create containerd configuration directory /etc/containerd
      file:
        path: /etc/containerd
        state: directory
        mode: 0755

    - name: Create /etc/containerd/config.toml
      file:
        path: /etc/containerd/config.toml
        state: touch

    - name: Generate containerd config and write it to /etc/containerd/config.toml
      become: false
      shell: containerd config default | sudo tee /etc/containerd/config.toml

    - name: Set SystemdCgroup as true in /etc/containerd/config.toml
      replace:  
        path: /etc/containerd/config.toml
        regexp: 'SystemdCgroup = false'
        replace: 'SystemdCgroup = true'

    - name: Verify SystemdCgroup setting
      command: grep 'SystemdCgroup' /etc/containerd/config.toml
      register: var_SystemdCgroup_output

    - debug:
        msg: |-
          {{ var_SystemdCgroup_output.stdout_lines }}

    - name: Download containerd.service file from GitHub
      get_url:
        url: "https://raw.githubusercontent.com/containerd/containerd/main/containerd.service"
        dest: /etc/systemd/system/containerd.service

    - name: Reload systemd daemon
      systemd:
        name: daemon-reload

    - name: Enable and start containerd.service
      systemd:
        name: containerd.service
        enabled: yes
        state: started
    
    - name: Verify status of containerd service
      command: systemctl is-active containerd
      register: containerd_service_info

    - debug:
        msg: |-
          {{ containerd_service_info.stdout_lines }}

    - name: Verify containerd version
      become: false
      command: containerd --version
      register: containerd_info

    - debug:
        msg: |-
          {{ containerd_info.stdout_lines }}


- name: Install latest version of runc using official binaries
  hosts: k8s_cluster_ctrl_plane_node, k8s_cluster_worker_nodes 
  become: true
  tasks:
    - name: Get latest version information of runc from GitHub API
      uri:
        url: https://api.github.com/repos/opencontainers/runc/releases/latest
        return_content: true
      register: var_runc_release

    - set_fact:
        var_runc_version: "{{ var_runc_release.json.tag_name }}"

    - debug:
        msg: |-
          Latest stable version to be installed of runc is {{ var_runc_version }}

    - name: Download runc binary and save it as /usr/local/bin/runc
      get_url:
        url: "https://github.com/opencontainers/runc/releases/download/{{ var_runc_version }}/runc.amd64"
        dest: /usr/local/bin/runc
        mode: 0755

    - name: Verify runc version
      become: false
      command: runc --version
      register: runc_info

    - debug:
        msg: |-
          {{ runc_info.stdout_lines }}

- name: Configure k8s repository to install kubelet, kubeadm and kubectl packages
  hosts: k8s_cluster_ctrl_plane_node, k8s_cluster_worker_nodes 
  become: true
  tasks:
    - name: Get latest version information of kubernetes from GitHub API
      uri:
        url: https://api.github.com/repos/kubernetes/kubernetes/releases/latest
        return_content: true
      register: var_k8s_release

    - set_fact:
        var_k8s_latest_version: "{{ var_k8s_release.json.tag_name }}"

    - debug:
        msg: |-
          Latest stable version to be installed of kubernetes is {{ var_k8s_latest_version }}

    - set_fact:
        var_k8s_version_strip_patch: "{{ var_k8s_latest_version | regex_replace('.[0-9]+$', '') }}"

    - when: ansible_os_family == "RedHat"
      block:
        - name: Add k8s rpm repository ( RedHat based systems ).
          yum_repository:
            description: k8s-{{ var_k8s_version_strip_patch }}
            name: k8s-{{ var_k8s_version_strip_patch }}
            baseurl: https://pkgs.k8s.io/core:/stable:/{{ var_k8s_version_strip_patch }}/rpm/
            gpgcheck: 1
            gpgkey: https://pkgs.k8s.io/core:/stable:/{{ var_k8s_version_strip_patch }}/rpm/repodata/repomd.xml.key
            enabled: true
            exclude:
              - kubelet
              - kubeadm
              - kubectl
            state: present

        - name: Install latest versions of kubelet, kubeadm and kubectl packages ( RedHat based systems ).
          dnf:
            update_cache: true
            name:
              - kubelet
              - kubectl 
              - kubeadm
            disable_excludes: k8s-{{ var_k8s_version_strip_patch }}
            state: present


    - when: ansible_os_family == "Debian"
      block:
        - name: Add k8s gpg apt-key ( Debian based systems ).
          apt_key:
            keyring: /etc/apt/keyrings/k8s-apt-keyring-{{ var_k8s_version_strip_patch }}.gpg
            url: https://pkgs.k8s.io/core:/stable:/{{ var_k8s_version_strip_patch }}/deb/Release.key
            state: present

        - name: Add k8s deb repository ( Debian based systems ).
          apt_repository:
            filename: k8s-{{ var_k8s_version_strip_patch }}
            repo: deb [signed-by=/etc/apt/keyrings/k8s-apt-keyring-{{ var_k8s_version_strip_patch }}.gpg] https://pkgs.k8s.io/core:/stable:/{{ var_k8s_version_strip_patch }}/deb/ /
            state: present
            update-cache: true

        - name: Install latest versions kubelet, kubeadm and kubectl packages ( Debian based systems ).
          apt:
            name:
              - kubelet
              - kubectl 
              - kubeadm
            state: present

        - name: Lock kubelet, kubeadm and kubectl packages from upgrades ( Debian based systems ).
          command: apt-mark hold kubelet kubeadm kubectl


    - when: ansible_os_family == "Suse"
      block:
        - name: Add k8s rpm repository and install kubelet, kubeadm and kubectl packages ( Suse based systems ).
          zypper_repository:
            description: k8s-{{ var_k8s_version_strip_patch }}
            name: k8s-{{ var_k8s_version_strip_patch }}
            repo: https://pkgs.k8s.io/core:/stable:/{{ var_k8s_version_strip_patch }}/rpm/
            auto_import_keys: true
            enabled: true
            state: present

        - name: Work-around for conntrack dependency issue with kubelet ( Suse based systems ).
          command: zypper install -y --force-resolution --allow-unsigned-rpm https://raw.githubusercontent.com/Muthukumar-Subramaniam/install-k8s-on-linux/main/suse/conntrack/conntrack-1.4.5-1.46.x86_64.rpm

        - name: Install latest versions of kubelet, kubeadm and kubectl packages ( Suse based systems ).
          zypper:
            update_cache: true
            name:
              - kubelet
              - kubectl 
              - kubeadm
            state: present

        - name: Lock kubelet, kubeadm and kubectl packages from upgrades ( Suse based systems ).
          command: zypper addlock kubelet kubeadm kubectl


- name: Enabling and starting kubelet service
  hosts: k8s_cluster_ctrl_plane_node, k8s_cluster_worker_nodes 
  become: true
  tasks:
    - name: Enable and start kubelet.service
      systemd:
        name: kubelet.service
        enabled: yes
        state: started
    
    - name: Check kubelet service status
      command: systemctl is-enabled kubelet
      register: kubelet_service_info

    - debug:
        msg: |-
          {{ kubelet_service_info.stdout_lines }}


- name: Reboot all the systems for some upgrades and configuration changes to take effect
  hosts: k8s_cluster_ctrl_plane_node, k8s_cluster_worker_nodes 
  become: true
  tasks:
    - name: Reboot executed and waiting for nodes to come online
      reboot:
        msg: Reboot initiated by Ansible Host
        connect_timeout: 30
        post_reboot_delay: 60
        reboot_command: reboot
        reboot_timeout: 600
        test_command: whoami && systemctl is-active containerd

- name: Install k8s cluster with kubeadm on control plane node 
  hosts: k8s_cluster_ctrl_plane_node
  become: false
  tasks:
    - name: Wait until k8s core images required for cluster creation are pulled
      command: sudo kubeadm config images pull

    - name: Create k8s cluster using kubeadm init
      command: sudo kubeadm init --pod-network-cidr={{ var_k8s_pod_network_cidr }}

    - name: Copy /etc/kubernetes/admin.conf to ~/.kube 
      shell: |
        mkdir -p /home/{{ ansible_user }}/.kube
        sudo cp -p /etc/kubernetes/admin.conf /home/{{ ansible_user }}/.kube/config
        sudo chown $(id -u {{ ansible_user }}):$(id -g {{ ansible_user }}) /home/{{ ansible_user }}/.kube/config

    - name: Wait for Kubernetes API server to be healthy
      shell: curl -skL https://localhost:6443/healthz
      register: var_api_server_health_status
      until: var_api_server_health_status.stdout.find("ok") != -1
      retries: 100
      delay: 5

    - name: Get latest version information of calico CNI from github API
      uri:
        url: https://api.github.com/repos/projectcalico/calico/releases/latest
        return_content: true
      register: var_calico_release

    - set_fact:
        var_calico_latest_version: "{{ var_calico_release.json.tag_name }}"

    - debug:
        msg: |-
          Latest stable version to be installed of calico CNI is {{ var_calico_latest_version }}

    - name: Applying calico CNI manifest using from GitHub 
      shell: kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/{{ var_calico_latest_version }}/manifests/calico.yaml

    - name: Wait for control-plane to get Ready
      shell: kubectl get nodes | grep -w " Ready "
      register: var_control_plane_ready_status
      retries: 100
      until: var_control_plane_ready_status.stdout.find("Ready") != -1
      delay: 5

    - name: K8s cluster control-plane node is Ready
      shell: kubectl get nodes
      register: var_nodes_status

    - debug:
        msg: |-
          {{ var_nodes_status.stdout_lines }}

    - name: Print join command and store the value to join the worker nodes
      command: sudo kubeadm token create --print-join-command
      register: var_kubeadm_join_command

    - debug:
        msg: |-
          {{ var_kubeadm_join_command.stdout_lines }}

    - name: Copy join command as /tmp/kubernetes_join_command.sh to Ansible Host
      become: true
      local_action: shell echo "{{ var_kubeadm_join_command.stdout_lines[0] }}" > /tmp/kubernetes_join_command.sh


- name: Register worker nodes with the k8s cluster with kubeadm join command
  hosts: k8s_cluster_worker_nodes
  become: true
  tasks:
    - name: Copy join command from Ansibl Host to the worker nodes
      copy:
        src: /tmp/kubernetes_join_command.sh
        dest: /tmp/kubernetes_join_command.sh
        mode: 0755

    - name: Join the worker nodes with k8s cluster
      command: sh /tmp/kubernetes_join_command.sh

- name: Successfully completed installation of k8s cluster with single control plane node and worker nodes provided
  hosts: k8s_cluster_ctrl_plane_node
  become: false
  tasks:
  - name: worker nodes have already joinded the cluster, will be Ready in few minutes
    shell: kubectl get nodes
    register: var_nodes_status

  - debug:
      msg: |-
          {{ var_nodes_status.stdout_lines }}

  - name: Wait for all worker nodes to get Ready
    shell: kubectl get nodes | grep -w "NotReady" | wc -l
    register: var_number_of_nodes_not_ready
    until: var_number_of_nodes_not_ready.stdout.find("0") != -1
    retries: 100
    delay: 5

  - name: k8s cluster nodes are Ready
    shell: kubectl get nodes
    register: var_nodes_status

  - debug:
      msg: |-
          {{ var_nodes_status.stdout_lines }}

########################### EOF ##########################################
