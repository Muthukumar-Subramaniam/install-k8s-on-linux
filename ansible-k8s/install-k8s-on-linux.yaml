- name: Upgrade system packages of all the cluster nodes
  hosts: k8s_cluster_ctrl_plane_node, k8s_cluster_worker_nodes 
  become: true
  tasks:
    - when: ansible_os_family == "RedHat"
      name: Upgrade the system packages ( RedHat based systems )
      dnf:
        update_cache: true
        name: "*"
        state: latest

    - when: ansible_os_family == "Debian"
      name: Upgrade the system packages ( Debian based systems )
      apt:
        update_cache: true
        upgrade: full
  
    - when: ansible_os_family == "Suse"
      name: Upgrade the system package ( Suse based systems )
      zypper:
        update_cache: true
        name: "*"
        state: latest


- name: Disable swap memory
  hosts: k8s_cluster_ctrl_plane_node, k8s_cluster_worker_nodes 
  become: true
  tasks:
    - name: Turn off swap if active
      command: swapoff -a

    - name: Disable swap in fstab
      command: sed -i '/swap/s/^/#/' /etc/fstab


- name: Load required kernel modules and kernel parameters
  hosts: k8s_cluster_ctrl_plane_node, k8s_cluster_worker_nodes 
  become: true
  tasks:
    - name: Load overlay kernel module
      command: modprobe overlay

    - name: Load br_netfilter kernel module
      command: modprobe br_netfilter

    - name: Create /etc/modules-load.d/k8s.conf for the above loaded modules to be persistent
      blockinfile:
        create: true
        path: /etc/modules-load.d/k8s.conf
        block: |
          overlay
          br_netfilter
        state: present

    - name: Create /etc/sysctl.d/k8s.conf and update required kernel parameters to be persistent
      blockinfile:
        create: true
        path: /etc/sysctl.d/k8s.conf
        block: |
          net.ipv4.ip_forward = 1
          net.bridge.bridge-nf-call-iptables = 1
          net.bridge.bridge-nf-call-ip6tables = 1
        state: present

    - name: Re-load the system kernel parameters
      command: sysctl --system


- name: Download, install and configure latest version of containered
  hosts: k8s_cluster_ctrl_plane_node, k8s_cluster_worker_nodes 
  become: true
  vars:
    var_containerd_temp_dir: "/tmp/containerd"
  tasks:
    - name: Get latest version information of containerd from github API
      uri:
        url: https://api.github.com/repos/containerd/containerd/releases/latest
        return_content: true
      register: var_containerd_release

    - set_fact:
        var_containerd_version: "{{ var_containerd_release.json.tag_name }}"

    - debug:
        msg: |-
          Latest stable version of containerd is {{ var_containerd_version }}

    - name: Create /tmp/containerd to download the containerd binary
      file:
        path: "{{ var_containerd_temp_dir }}"
        state: directory
        mode: 0755

    - name: Download tarball of containerd binary from their official github repository
      get_url:
        url: https://github.com/containerd/containerd/releases/download/{{ var_containerd_version }}/containerd-{{ var_containerd_version | regex_replace('v', '') }}-linux-amd64.tar.gz
        dest: "{{ var_containerd_temp_dir }}/containerd.tar.gz"

    - name: Extract containerd tarball
      unarchive:
        remote_src: true
        src: "{{ var_containerd_temp_dir }}/containerd.tar.gz"
        dest: "{{ var_containerd_temp_dir }}"

    - name: Make containerd binaries executable
      file:
        path: "{{ var_containerd_temp_dir }}/bin/*"
        mode: +x
        recurse: yes

    - name: Copy containerd binary to system path /usr/local/bin/
      copy:
        remote_src: true
        src: "{{ var_containerd_temp_dir }}/bin/"
        dest: /usr/local/bin/
        owner: root
        group: root

    - name: Clean up /tmp/containerd
      file:
        path: "{{ var_containerd_temp_dir }}"
        state: absent

    - name: Create containerd configuration directory /etc/containerd
      file:
        path: /etc/containerd
        state: directory
        mode: 0755

    - name: Generate containerd config and write it to /etc/containerd/config.toml
      become: false
      command: sh -c "containerd config default | sudo tee /etc/containerd/config.toml"

    - name: Set SystemdCgroup as true in /etc/containerd/config.toml
      command: sed -i "/SystemdCgroup/s/false/true/g" /etc/containerd/config.toml

    - name: Verify SystemdCgroup setting
      command: grep 'SystemdCgroup' /etc/containerd/config.toml
      register: var_SystemdCgroup_output

    - debug:
        msg: |-
          {{ var_SystemdCgroup_output.stdout }}

    - name: Download containerd.service file from GitHub and save it as /etc/systemd/system/containerd.service
      get_url:
        url: "https://raw.githubusercontent.com/containerd/containerd/main/containerd.service"
        dest: /etc/systemd/system/containerd.service

    - name: Reload systemd daemon
      systemd:
        name: daemon-reload

    - name: Enable and start containerd.service
      systemd:
        name: containerd.service
        enabled: yes
        state: started
    
    - name: Check containerd service status
      command: systemctl is-active containerd
      register: containerd_service_info

    - debug:
        msg: "containerd.service status: {{ containerd_service_info }}"

    - name: Verify containerd version
      become: false
      command: containerd --version
      register: containerd_info

    - debug:
        msg: |-
          {{ containerd_info.stdout }}


- name: Download and install latest version of runc
  hosts: k8s_cluster_ctrl_plane_node, k8s_cluster_worker_nodes 
  become: true
  tasks:
    - name: Get latest version information of runc from github API
      uri:
        url: https://api.github.com/repos/opencontainers/runc/releases/latest
        return_content: true
      register: var_runc_release

    - set_fact:
        var_runc_version: "{{ var_runc_release.json.tag_name }}"

    - debug:
        msg: |-
          Latest stable version of runc is {{ var_runc_version }}

    - name: Download runc binary and save it as /usr/local/bin/runc
      get_url:
        url: "https://github.com/opencontainers/runc/releases/download/{{ var_runc_version }}/runc.amd64"
        dest: /usr/local/bin/runc
        mode: 0755  # Set executable permissions

    - name: Verify runc version
      become: no
      command: runc --version
      register: runc_info

    - debug:
        msg: |-
          {{ runc_info.stdout }}

- name: Configure official k8s repository and install kubelet, kubeadm and kubectl packages.
  hosts: k8s_cluster_ctrl_plane_node, k8s_cluster_worker_nodes 
  become: true
  tasks:
    - name: Get latest version information of kubernetes from github API
      uri:
        url: https://api.github.com/repos/kubernetes/kubernetes/releases/latest
        return_content: true
      register: var_k8s_release

    - set_fact:
        var_k8s_latest_version: "{{ var_k8s_release.json.tag_name }}"

    - debug:
        msg: |-
          Latest stable version of kubernetes is {{ var_k8s_latest_version }}

    - set_fact:
        var_k8s_version_strip_patch: "{{ var_k8s_latest_version | regex_replace('.[0-9]+$', '') }}"

    - when: ansible_os_family == "RedHat"
      name: Add k8s rpm repository ( RedHat based systems ).
      yum_repository:
        description: k8s-{{ var_k8s_version_strip_patch }}
        name: k8s-{{ var_k8s_version_strip_patch }}
        baseurl: https://pkgs.k8s.io/core:/stable:/{{ var_k8s_version_strip_patch }}/rpm/
        gpgcheck: 1
        gpgkey: https://pkgs.k8s.io/core:/stable:/{{ var_k8s_version_strip_patch }}/rpm/repodata/repomd.xml.key
        enabled: true
        exclude:
          - kubelet
          - kubeadm
          - kubectl
        state: present

    - when: ansible_os_family == "RedHat"
      name: Install latest versions of kubelet, kubeadm and kubectl packages ( RedHat based systems ).
      dnf:
        update_cache: true
        name:
          - kubelet
          - kubectl 
          - kubeadm
        disable_excludes: k8s-{{ var_k8s_version_strip_patch }}
        state: latest


    - when: ansible_os_family == "Debian"
      name: Add k8s gpg apt-key ( Debian based systems ).
      apt_key:
        keyring: /etc/apt/keyrings/k8s-apt-keyring-{{ var_k8s_version_strip_patch }}.gpg
        url: https://pkgs.k8s.io/core:/stable:/{{ var_k8s_version_strip_patch }}/deb/Release.key
        state: present

    - when: ansible_os_family == "Debian"
      name: Add k8s deb repository ( Debian based systems ).
      apt_repository:
        filename: k8s-{{ var_k8s_version_strip_patch }}
        repo: deb [signed-by=/etc/apt/keyrings/k8s-apt-keyring-{{ var_k8s_version_strip_patch }}.gpg] https://pkgs.k8s.io/core:/stable:/{{ var_k8s_version_strip_patch }}/deb/ /
        state: present
        update-cache: true

    - when: ansible_os_family == "Debian"
      name: Install latest versions kubelet, kubeadm and kubectl packages ( Debian based systems ).
      apt:
        name:
          - kubelet
          - kubectl 
          - kubeadm
        state: latest
    - when: ansible_os_family == "Debian"
      name: Lock kubelet, kubeadm and kubectl packages from upgrades ( Debian based systems ).
      command: apt-mark hold kubelet kubeadm kubectl


    - when: ansible_os_family == "Suse"
      name: Add k8s rpm repository and install kubelet, kubeadm and kubectl packages ( Suse based systems ).
      zypper_repository:
        description: k8s-{{ var_k8s_version_strip_patch }}
        name: k8s-{{ var_k8s_version_strip_patch }}
        repo: https://pkgs.k8s.io/core:/stable:/{{ var_k8s_version_strip_patch }}/rpm/
        auto_import_keys: true
        enabled: true
        state: present

    - when: ansible_os_family == "Suse"
      name: Work-around for conntrack dependency issue with kubelet ( Suse based systems ).
      command: zypper install -y --force-resolution --allow-unsigned-rpm https://raw.githubusercontent.com/Muthukumar-Subramaniam/install-k8s-on-linux/main/suse/conntrack/conntrack-1.4.5-1.46.x86_64.rpm

    - when: ansible_os_family == "Suse"
      name: Install latest versions of kubelet, kubeadm and kubectl packages ( Suse based systems ).
      zypper:
        update_cache: true
        name:
          - kubelet
          - kubectl 
          - kubeadm
        state: latest

    - when: ansible_os_family == "Suse"
      name: Lock kubelet, kubeadm and kubectl packages from upgrades ( Suse based systems ).
      command: zypper addlock kubelet kubeadm kubectl


- name: Enabling and starting kubelet service
  hosts: k8s_cluster_ctrl_plane_node, k8s_cluster_worker_nodes 
  become: true
  tasks:
    - name: Enable and start kubelet.service
      systemd:
        name: kubelet.service
        enabled: yes
        state: started
    
    - name: Check kubelet service status
      command: systemctl is-enabled kubelet
      register: kubelet_service_info

    - debug:
        msg: |-
          {{ kubelet_service_info }}


- name: Reboot all the systems for some upgrades and configuration changes to take effect
  hosts: k8s_cluster_ctrl_plane_node, k8s_cluster_worker_nodes 
  become: true
  tasks:
    - name: Reboot the systems and wait for the systems to come back online
      reboot:
        msg: Reboot initiated by Ansible Controller Host
        connect_timeout: 30
        post_reboot_delay: 60
        reboot_command: reboot
        reboot_timeout: 120
        test_command: whoami && systemctl is-active containerd

- name: Install k8s cluster with kubeadm on control plane node 
  hosts: k8s_cluster_ctrl_plane_node
  become: false
  tasks:
    - name: Pull core images to install k8s cluster
      command: sudo kubeadm config images pull

    - name: Create k8s cluster with kubeadm init --pod-network-cidr=10.8.0.0/16
      command: sudo kubeadm init --pod-network-cidr=10.8.0.0/16

    - name: Copy /etc/kubernetes/admin.conf to ~/.kube 
      shell: |
        mkdir -p /home/{{ ansible_user }}/.kube
        sudo cp -p /etc/kubernetes/admin.conf /home/{{ ansible_user }}/.kube/config
        sudo chown $(id -u {{ ansible_user }}):$(id -g {{ ansible_user }}) /home/{{ ansible_user }}/.kube/config

    - name: Wait for Kubernetes API server to be healthy
      shell: curl -skL https://localhost:6443/healthz
      register: var_api_server_health_check_result
      until: var_api_server_health_check_result.stdout.find("ok") != -1
      retries: 10000
      delay: 5

    - name: Get latest version information of calico CNI from github API
      uri:
        url: https://api.github.com/repos/projectcalico/calico/releases/latest
        return_content: true
      register: var_calico_release

    - set_fact:
        var_calico_latest_version: "{{ var_calico_release.json.tag_name }}"

    - debug:
        msg: |-
          Latest stable version of calico CNI is {{ var_calico_latest_version }}

    - name: Applying calico CNI manifest using GitHub URL 
      command: kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/{{ var_calico_latest_version }}/manifests/calico.yaml

    - name: Wait for control-plane to get Ready"
      shell: kubectl get nodes | grep -w " Ready "
      register: var_control_plane_ready_status
      retries: 100000
      until: var_control_plane_ready_status.stdout.find("Ready") != -1
      delay: 5

    - name: Get latest version information of k8s csi-smb-driver from github API
      uri:
        url: https://api.github.com/repos/kubernetes-csi/csi-driver-smb/releases/latest
        return_content: true
      register: var_csi_driver_smb_release

    - set_fact:
        var_csi_driver_smb_latest_version: "{{ var_csi_driver_smb_release.json.tag_name }}"

    - debug:
        msg: |-
          Latest stable version of k8s csi-driver-smb is {{ var_csi_driver_smb_latest_version }}

    - name: Install CSI SMB drivers by remote from GitHub using kubectl
      shell: curl -skSL https://raw.githubusercontent.com/kubernetes-csi/csi-driver-smb/{{ var_csi_driver_smb_latest_version }}/deploy/install-driver.sh | bash -s {{ var_csi_driver_smb_latest_version }} --

    - name: Print join command and store the value to join the worker nodes
      command: sudo kubeadm token create --print-join-command
      register: var_kubeadm_join_command

    - debug:
        msg: |-
          {{ var_kubeadm_join_command.stdout }}

    - name: Copy join command to local file /tmp/kubernetes_join_command.sh 
      become: true
      local_action: shell echo "{{ var_kubeadm_join_command.stdout_lines[0] }}" > /tmp/kubernetes_join_command.sh


- name: Register worker nodes with the k8s cluster with kubeadm join command
  hosts: k8s_cluster_worker_nodes
  become: true
  tasks:
    - name: Copy join command from Ansiblehost to the worker nodes.
      copy:
        src: /tmp/kubernetes_join_command.sh
        dest: /tmp/kubernetes_join_command.sh
        mode: 0755

    - name: Join the worker node with k8s cluster
      command: sh /tmp/kubernetes_join_command.sh

- name: Successfully completed installation of k8s cluster with single control plane node and worker nodes provided
  hosts: k8s_cluster_ctrl_plane_node
  become: false
  tasks:
    - name: worker nodes have already joinded the cluster, will be ready in few minutes
      command: kubectl get nodes
      register: var_k8s_nodes_status

    - debug:
        msg: |-
          {{ var_k8s_nodes_status.stdout_lines }}

########################### EOF ##########################################
